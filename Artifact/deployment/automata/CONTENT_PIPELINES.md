# Content Pipelines & Database Inventory

This document inventories the current database tables used by the AI surface (context & reflection) and documents recommended content pipelines so we do not lose context.

---

## 1) Current DB Tables (Context Engine)
These tables are created by `ai_engine/context_engine.py` (see `_init_database`).

- `context_entries`
  - Columns: `id TEXT PRIMARY KEY`, `timestamp TEXT`, `role TEXT`, `content TEXT`, `token_count INTEGER`, `metadata TEXT`, `created_at TEXT`
  - Purpose: Stores raw context entries (user/assistant/system/tool) and is the primary memory store used to build prompts.
  - Notes: `metadata` is JSON-encoded; token counts are a rough estimate used for truncation logic.

- `context_summaries`
  - Columns: `id`, `timestamp`, `original_token_count`, `summary_token_count`, `summary`, `entry_count`, `time_range_start`, `time_range_end`, `created_at`
  - Purpose: Stores summaries generated when old entries are truncated into compact summaries.

- `meta_summaries`
  - Columns: `id`, `timestamp`, `summary_count`, `total_original_tokens`, `meta_summary`, `time_range_start`, `time_range_end`, `created_at`
  - Purpose: High-level summaries across multiple `context_summaries` used for long-term memory.

- `context_analytics`
  - Columns: `timestamp`, `entry_count`, `token_count`, `role_distribution`, `topic_tags`, `performance_metrics`, `created_at`
  - Purpose: A small time-series ledger for analytics (e.g., growth of memory, role distribution).

- `reflections`
  - Columns: `id`, `timestamp`, `context_snapshot`, `reflection`, `improvements`, `action_items`, `created_at`
  - Purpose: Outputs from ReflectionEngine — stores self-reflections, identified improvements and actions.

- `context_embeddings`
  - Columns: `entry_id`, `embedding`, `created_at` (embedding stored as JSON string)
  - Purpose: Precomputed embeddings for similarity search when Hektor is not available.

---

## 2) Current Content Storage / Artifacts
- Drafts: CLI currently saves drafts as JSON files
  - `Artifact/research_outputs/articles/draft_<timestamp>_<i>.json` or `.md` (via `Artifact/tools/generate_articles.py`)
- Final Articles: Editorial pipeline saves final Markdown files
  - `Artifact/deployment/research_outputs/articles/final_<timestamp>_<i>.md`
- Batch summaries: `Artifact/deployment/research_outputs/articles/summary_<timestamp>.md`

Notes: There is currently no database table tracking draft/final article lifecycle (status, author, tags, publish scheduling). We should add one for robust pipelines.

---

## 3) Recommended DB additions (content tracking)
Add a `content_items` table to track lifecycle of content drafts and final versions.

Suggested schema (SQLite):
```
CREATE TABLE IF NOT EXISTS content_items (
  id TEXT PRIMARY KEY,
  platform TEXT,
  topic TEXT,
  status TEXT,          -- draft | editorial | final | published | failed
  content_json TEXT,    -- raw JSON generated by provider
  text TEXT,            -- extracted primary text (for search)
  title TEXT,
  author TEXT,
  tags TEXT,            -- CSV or JSON string
  model TEXT,
  tokens INTEGER,
  export_path TEXT,     -- path to final markdown if exported
  batch_id TEXT,        -- group editorial runs
  created_at TEXT DEFAULT CURRENT_TIMESTAMP,
  updated_at TEXT
)
```

Benefits:
- Track status & ownership of drafts
- Allow UI to list drafts and accelerate editorial work
- Easier to implement publish scheduling and retries

---

## 4) Pipeline definitions (per table)

### A. Content Generation Pipeline (Drafts)
- Trigger: `/api/content/generate` or CLI `generate_articles.py`
- Steps:
  1. Generate content via `ContentGenerator.generate` → returns JSON `{'content': {...}}`.
  2. Save as `content_items` with `status='draft'` (if exist; otherwise save as file).
  3. Add a `context_entries` entry (role=assistant) summarizing the draft for memory.
  4. Optionally schedule editorial job or UI action.
- End result: Draft tracked in DB + file (optional).

### B. Editorial Pipeline (Draft → Final)
- Trigger: `/api/content/editorial` or `--finalize` flag in CLI
- Steps:
  1. Retrieve drafts (from `content_items` with status 'draft' or from files).
  2. Run AI improvement step (editor prompt) to produce structured JSON (title, article/markdown, summary, tags, author).
  3. Save final article as Markdown to `Artifact/.../articles/final_*.md` and set `content_items.status='final'` and `export_path` to file path.
  4. Create a `context_entries` note and a `reflection` if the editorial step suggests improvements.
  5. Generate a batch summary file and attach `batch_id` to content_items.
- End result: Final files written, `content_items` updated with metadata and status.

### C. Publish Pipeline
- Trigger: Manual or scheduled publish action
- Steps:
  1. Convert final article to platform-specific payload.
  2. Schedule via social posting subsystem (enqueue job, set `status='published'` on success)
  3. Record analytics and add `context_entries` for post outcome.
- End result: Article published and tracked.

### D. Reflection & Meta Pipeline
- Trigger: periodic or manual `/api/context/reflect`
- Steps:
  1. ReflectionEngine analyzes `context_entries` and `reflections`.
  2. Save improvements and action items to `reflections` table.
  3. Optionally tag `content_items` or schedule rewrites based on identified improvements.
- End result: System improves prompts, templates, or content styles over time.

### E. Similarity / Embedding Pipeline
- Trigger: `ContextEngine.add_entry` or periodic reindex
- Steps:
  1. If Hektor available: index into Hektor vector DB.
  2. Else: compute embedding with provider and write to `context_embeddings`.
  3. Periodically re-run nearest-neighbor / scoring jobs for analytics or topic clustering.

---

## 5) Endpoint and Task Additions (short list)
- DB migration: add `content_items` table. (SQL file + code path to insert/upgrade)
- Endpoints:
  - `GET /api/content/drafts` — list drafts (filter by status)
  - `POST /api/content/drafts` — create draft from payload (or accept provider-side id)
  - `POST /api/content/drafts/<id>/finalize` — run editorial pipeline for a single draft
  - `POST /api/content/publish` — publish a final article to a platform
- Background jobs/worker:
  - `editorial_worker` — picks up `draft` items, runs editorial improvements, writes final files
  - `embedding_worker` — computes & stores embeddings (if Hektor missing)

---

## 6) Next action items
1. Implement `content_items` schema + migration and add CRUD helpers (DAO). (High priority)
2. Add endpoints to list/create/finalize/publish content items. (High priority)
3. Add unit tests for generation + editorial flows writing to DB and files. (Medium)
4. Add UI controls to list drafts and trigger finalize per-draft. (Low)
5. Document the publish step and schedule options for each platform (Medium).

---

## 7) Where artifacts live (quick reference)
- Drafts (CLI): `Artifact/research_outputs/articles/draft_*.json` or `.md`
- Final articles: `Artifact/deployment/research_outputs/articles/final_*.md`
- Batch summaries: `Artifact/deployment/research_outputs/articles/summary_*.md`
- Context DB: `~/.automata/context.db` (contains context_* tables)

---

If you want, I can now create the DB migration and the `content_items` table and wire the necessary endpoints and tests — next step is to add a migration + model + simple CRUD endpoints and a worker to move `draft` → `final` status. Let me know if you want me to proceed and which pieces to prioritize.
